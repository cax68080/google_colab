{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"８章_深層学習による画像認識とその仕組みを知ろう_(6-10節).ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XTcc5It-hrUx"},"source":["# 第8章 深層学習による画像認識とその仕組みを知ろう\n","\n","ここでは、深層学習を学ぶうえで必要なプログラムを実行していく流れを学んでいきます。  \n","Google Colaboratory上で実行する場合、”ランタイム”から”ランタイムのタイプの変更”を開きGPUが選択されている事を確認して下さい。\n","\n","※エラーが出る場合は、Clear Output を行うことで正常に動く場合があります。"]},{"cell_type":"code","metadata":{"id":"NYh6G8m2bJcG"},"source":["#Colaboratory環境の設定\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/MathProgramming/Chapter8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBNOcz49izlG"},"source":["#ライブラリの設定\n","!pip install -q -r ./requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1vVkNz39hrU2"},"source":["## 8-6 学習データとしての画像の構造を理解しよう\n"]},{"cell_type":"code","metadata":{"id":"PB3j1AhUhrU2"},"source":["from tensorflow.keras.datasets import cifar10\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# cifar10と言うデータセットを使う。\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print(\"x_train.shape: \",x_train.shape)\n","print(\"y_train.shape: \",y_train.shape)\n","print(\"x_test.shape: \",x_test.shape)\n","print(\"y_test.shape: \",y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvZ8F2uyhrU4"},"source":["print(\"shape: \",x_train[0].shape)\n","print(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"v1fFoFswhrU4"},"source":["#学習データの最初の画像を表示\n","plt.imshow(x_train[0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1lxB_pUhrU5"},"source":["#学習データの一番最初の画像のラベルを表示\n","print(y_train[0])\n","\n","#学習データ、テストデータのラベルが取りうる値を列挙\n","print(np.unique(y_train))\n","print(np.unique(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcT1GXkEiX-H"},"source":["#ラベルの番号と名前を対応付ける。例えばラベルが６ならlabel_names[6]で、frogになる。\n","label_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n","\n","plt.figure(figsize=(10,5))\n","for index in range(10):\n","    img = x_train[index]\n","    label = label_names[y_train[index][0]]\n","    plt.subplot(2,5,index+1)\n","    plt.title(label)\n","    plt.axis(\"off\")\n","    plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m54sSPzXhrU5"},"source":["## 8-7 深層学習ライブラリを使ってゼロから画像データを学習してみよう\n"]},{"cell_type":"code","metadata":{"id":"NUTSY-_ZhrU5"},"source":["from tensorflow.keras.utils import to_categorical\n","\n","#画像の各ピクセルの値が0~1の間の値を取るようにする\n","x_train = x_train.astype('float32')/255\n","x_test = x_test.astype('float32')/255\n","\n","#ラベルのOnehot encodingを行う\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSHYry1PhrU9"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n","\n","#モデルの構築\n","model = Sequential()\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=x_train.shape[1:], activation='relu', name=\"conv2d_1\"))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='valid'))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', input_shape=x_train.shape[1:], activation='relu', name=\"conv2d_2\"))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='valid'))\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dense(len(label_names), activation='softmax'))\n","\n","#モデルの概要を表示\n","print(model.summary())\n","\n","model.compile(optimizer = optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0kEOg_RhrU-"},"source":["batch_size = 64\n","epochs=20\n","\n","#学習開始\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXhMF7B4hrU-"},"source":["#正答率を計算\n","y_pred = model.predict(x_test)\n","y_pred_classes = np.argmax(y_pred,axis = 1) \n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","\n","print(test_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jb8hpBoYhrU_"},"source":["## 8-8 学習した結果を評価しよう"]},{"cell_type":"code","metadata":{"id":"L24ISpi6hrVA"},"source":["fig, ax = plt.subplots(2,1)\n","ax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\n","ax[0].plot(history.history['val_loss'], color='g', label=\"Validation Loss\")\n","legend = ax[0].legend()\n","\n","ax[1].plot(history.history['accuracy'], color='b', label=\"Training Accuracy\")\n","ax[1].plot(history.history['val_accuracy'], color='g', label=\"Validation Accuracy\")\n","legend = ax[1].legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V82MdSzOhrVA"},"source":["from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n","import seaborn as sns\n","\n","y_pred = model.predict(x_test)\n","#y_predは、各クラスになる確率が入っているのでそれぞれで最大値だけを取る\n","y_pred_classes = np.argmax(y_pred,axis = 1) \n","y_true = np.argmax(y_test,axis = 1)\n","cf_matrix = confusion_matrix(y_true, y_pred_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCJMFLqbhrVB"},"source":["plt.figure(figsize=(13, 13))\n","c = sns.heatmap(cf_matrix, annot=True,fmt=\"d\")\n","c.set(xticklabels=label_names, yticklabels=label_names)\n","plt.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oD4_HOJmhrVB"},"source":["## 8-9 学習したネットワークが見ている「特徴」を可視化してみよう"]},{"cell_type":"code","metadata":{"id":"YWkGX8HhhrVB"},"source":["from tensorflow.keras import backend as K\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from matplotlib import colors\n","from PIL import Image\n","\n","def grad_cam_image(model, layer_name, image):\n","  \n","  with tf.GradientTape() as tape:\n","    layer = model.get_layer(layer_name)\n","\n","    #出力を、普通の出力（１０個に分類する出力）と、layer_nameで指定した層の出力の２つにする。\n","    tmpModel = Model([model.inputs], [model.output, layer.output])\n","    #model_outは入力した画像の分類結果。\n","    #layer_outはlayer_nameで指定した層の出力\n","    model_out, layer_out = tmpModel(np.array([image]))\n","\n","    #モデルの分類結果で一番高い確率をclass_outに格納\n","    class_out = model_out[:, np.argmax(model_out[0])]\n","    #出力から、指定した層までの勾配を計算\n","    grads = tape.gradient(class_out, layer_out)\n","    #勾配の平均を取る. Global Average Poolingと同じこと。\n","    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n","\n","\n","  #計算した勾配の平均を指定した層の出力にかける\n","  heatmap = tf.multiply(pooled_grads, layer_out)\n","  #チャンネル毎に足し合わせる\n","  heatmap = tf.reduce_sum(heatmap, axis=-1)\n","  #マイナスの値を取らないようにする。ReLuと同じ処理\n","  heatmap = np.maximum(heatmap, 0)\n","  #0~1の値に収める\n","  heatmap = heatmap/heatmap.max()\n","\n","  #見やすい画像にする\n","  return_image = np.asarray(Image.fromarray(heatmap[0]).resize(image.shape[:2])) * 255\n","  colormap = plt.get_cmap('jet')\n","  return_image = return_image.reshape(-1)\n","  return_image = np.array([colormap(int(np.round(pixel)))[:3] for pixel in return_image]).reshape(image.shape)\n","  return_image = image * 0.5 + return_image * 0.5\n","\n","  return return_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dM8mu9-4mxV9"},"source":["[layer.name for layer in model.layers]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSmulzH8hrVC"},"source":["grad_cam = grad_cam_image(model, \"conv2d_2\", x_train[0])\n","\n","plt.figure(figsize=(10,5))\n","plt.subplot(1,2,1)\n","plt.imshow(grad_cam)\n","\n","plt.subplot(1,2,2)\n","plt.imshow(x_train[0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fajcdxaGhrVC"},"source":["## 8-10 学習したネットワークの中身を可視化してみよう"]},{"cell_type":"code","metadata":{"id":"cHqkocethrVC"},"source":["def show_filters(model, layer_name):\n","    target_layer = model.get_layer(layer_name).get_weights()[0]\n","    filter_num = target_layer.shape[3]\n","\n","    plt.figure(figsize=(15, 10))\n","    for i in range(filter_num):\n","        plt.subplot(int(filter_num/6) + 1, 6, i+1)\n","        plt.title('filter %d' % i)\n","        plt.axis('off')\n","        plt.imshow(target_layer[ :, :, 0, i], cmap=\"gray\") \n","    plt.show()\n","    \n","show_filters(model, \"conv2d_1\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CuVSHc1ehrVC"},"source":["from tensorflow.keras.models import Model\n","\n","#モデルと画像を渡すと、各畳み込み層での出力を画像として表示する。\n","def layer_outputs(model, image):\n","    #畳み込み層のみ抽出\n","    _model = Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers if type(layer) is Conv2D])\n","\n","    #渡された画像の分類を実行\n","    conv_outputs = _model.predict(np.array([image]))\n","    \n","    def show_images(output, title):\n","        output = output[0]\n","        filter_num = output.shape[2]\n","        \n","        fig = plt.figure(figsize=(20, 15))\n","        fig.suptitle(title, size=15)\n","        for i in range(filter_num):\n","            plt.subplot(int(filter_num/8) + 1, 8, i+1)\n","            plt.title('filter %d' % i)\n","            plt.axis('off')\n","            plt.imshow(output[:,:,i])\n","    \n","    #畳み込み層毎に画像を出力\n","    for i, output in enumerate(conv_outputs):\n","        title = \"Conv layer number %d\" % (i + 1)\n","        show_images(output, title)\n","        \n","layer_outputs(model, x_train[0])"],"execution_count":null,"outputs":[]}]}