{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"２章_機械学習を使った分析を行ってみよう.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"G05khoYXUHXS"},"source":["# 第2章 機械学習を使った分析を行ってみよう\n","ここでは、機械学習の基礎を学ぶうえで必要なプログラムを実行していく流れを学んでいきます。  "]},{"cell_type":"code","metadata":{"id":"KjfC8pieUOwc"},"source":["#Colaboratory環境の設定\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/MathProgramming/Chapter2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bBzz642b6G4H"},"source":["#ライブラリの設定\n","!pip install -q -r ./requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x3CobWhIUHXY"},"source":["## 2-1 顧客の行動パターンの類似度を計算しよう"]},{"cell_type":"markdown","metadata":{"id":"acfi69TYUHXY"},"source":["### データ読み込み"]},{"cell_type":"code","metadata":{"id":"-U-LjBpnUHXZ"},"source":["import pandas as pd\n","df_info = pd.read_csv(\"accomodation_info.csv\", index_col=0, parse_dates=[0])\n","df_info"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YoNr2MDhUHXa"},"source":["### 特徴ベクトル可視化（特徴ベクトルとして利用回数の時系列データを利用）"]},{"cell_type":"code","metadata":{"id":"5Yexsj1WUHXa"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","# indexの抽出\n","x_0 = df_info.resample('M').count()\n","x_0 = x_0.drop(x_0.columns.values,axis=1)\n","# 順位の設定\n","i_rank = 1\n","j_rank = 2\n","# 顧客IDの抽出\n","i_id = df_info['顧客ID'].value_counts().index[i_rank]\n","j_id = df_info['顧客ID'].value_counts().index[j_rank]\n","# 月ごとの利用回数を特徴量として抽出\n","x_i = df_info[df_info['顧客ID']==i_id].resample('M').count()\n","x_j = df_info[df_info['顧客ID']==j_id].resample('M').count()\n","# 欠損値があった場合の穴埋め\n","x_i = pd.concat([x_0, x_i], axis=1).fillna(0)\n","x_j = pd.concat([x_0, x_j], axis=1).fillna(0)\n","# 描画\n","plt.plot(x_i)\n","plt.plot(x_j)\n","plt.xticks(rotation=60)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6oogRDBTUHXb"},"source":["### 類似度計算"]},{"cell_type":"code","metadata":{"id":"Lm6EQj2jUHXb"},"source":["import pandas as pd\n","import numpy as np\n","# 特徴ベクトルの差を計算\n","dx = x_i.iloc[:,0].values-x_j.iloc[:,0].values\n","# ベクトルノルム（距離）を計算\n","n = np.linalg.norm(dx)\n","# 次元による正規化\n","num_dim = len(x_i)\n","d = n/num_dim\n","print(\"類似度:\",d)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQqH8DXjUHXb"},"source":["## 2-3 大口顧客の類似性を主成分分析によって確認しよう"]},{"cell_type":"markdown","metadata":{"id":"Dst70CqgUHXc"},"source":["### 特徴ベクトル抽出"]},{"cell_type":"code","metadata":{"id":"MkXiSKB0UHXc"},"source":["import pandas as pd\n","# indexの調整\n","x_0 = df_info.resample('M').count()\n","x_0 = x_0.drop(x_0.columns.values,axis=1)\n","# 配列を準備\n","list_vector = []\n","# 人数の設定\n","num = 100\n","for i_rank in range(num):\n","    # 顧客IDの抽出\n","    i_id = df_info['顧客ID'].value_counts().index[i_rank]\n","    # 月ごとの利用回数を特徴量として抽出\n","    x_i = df_info[df_info['顧客ID']==i_id].resample('M').count()\n","    # 欠損値があった場合の穴埋め\n","    x_i = pd.concat([x_0, x_i], axis=1).fillna(0)\n","    # 特徴ベクトルとして追加\n","    list_vector.append(x_i.iloc[:,0].values.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5u3BImAxUHXc"},"source":["### 主成分分析(PCA)による可視化"]},{"cell_type":"code","metadata":{"id":"MPUTuGdfUHXc"},"source":["from sklearn.decomposition import PCA\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# 特徴ベクトルを変換\n","features = np.array(list_vector)\n","# 主成分分析を実施\n","pca = PCA()\n","pca.fit(features)\n","# 特徴ベクトルを主成分に変換\n","transformed = pca.fit_transform(features)\n","# 可視化\n","for i in range(len(transformed)):\n","    plt.scatter(transformed[i,0],transformed[i,1],color=\"k\")\n","    plt.text(transformed[i,0],transformed[i,1],str(i))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GKypESOIUHXd"},"source":["## 2-4. 大口顧客の行動パターンを時系列によって確かめよう"]},{"cell_type":"code","metadata":{"id":"ECSos2_RUHXd"},"source":["import pandas as pd\n","# indexの抽出\n","x_0 = df_info.resample('M').count()\n","x_0 = x_0.drop(x_0.columns.values,axis=1)\n","\n","# 順位の設定\n","list_rank = [0,1,2]\n","x = []\n","for i_rank in list_rank:\n","    # 顧客IDの抽出\n","    i_id = df_info['顧客ID'].value_counts().index[i_rank]\n","    # 月ごとの利用回数を特徴量として抽出\n","    x_i = df_info[df_info['顧客ID']==i_id].resample('M').count()\n","    # 欠損値があった場合の穴埋め\n","    x_i = pd.concat([x_0, x_i], axis=1).fillna(0)\n","    # 描画\n","    plt.plot(x_i)\n","    plt.xticks(rotation=60)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWVPIRFoUHXd"},"source":["## 2-5. 大口顧客同士の行動パターンの違いをクラスタリングによって可視化しよう"]},{"cell_type":"markdown","metadata":{"id":"GsbOiUq9UHXd"},"source":["### クラスタリング(k-means法)による分類"]},{"cell_type":"code","metadata":{"id":"7wsexxcYUHXe"},"source":["from sklearn.cluster import KMeans\n","# クラスター数を設定\n","num_of_cluster = 4\n","# クラスターに分類\n","model = KMeans(n_clusters=num_of_cluster, random_state=0)\n","model.fit(features)\n","pred_class = model.labels_\n","print(pred_class)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ou_N9uB1UHXe"},"source":["### 主成分分析(PCA)による可視化"]},{"cell_type":"code","metadata":{"id":"Vri7zIMZUHXe"},"source":["from sklearn.decomposition import PCA\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 主成分分析を実施\n","pca = PCA()\n","pca.fit(features)\n","# 特徴ベクトルを主成分に変換\n","transformed = pca.fit_transform(features)\n","# 可視化\n","plt.figure(figsize=(12, 8))\n","plt.scatter(transformed[:,0],transformed[:,1],c=pred_class)\n","for i in range(len(transformed)):\n","    text = str(i) + \"(\" + str(pred_class[i]) + \")\"\n","    plt.text(transformed[i,0],transformed[i,1],text)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCIipONxUHXf"},"source":["## 2-6. 決定木によって行動の原因を推定してみよう"]},{"cell_type":"markdown","metadata":{"id":"mipZlPgWUHXf"},"source":["### 目的変数の設定"]},{"cell_type":"code","metadata":{"id":"7lhJ2Ni1UHXf"},"source":["import numpy as np\n","# 分析したいクラスを設定する\n","target_class = 1\n","# 目的変数を作成する\n","num = len(pred_class)\n","data_o = np.zeros(num)\n","for i in range(num):\n","    if pred_class[i]==target_class:\n","        data_o[i] = True\n","    else:\n","        data_o[i] = False\n","print(data_o)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yjWWlM__UHXf"},"source":["### 説明変数の設定"]},{"cell_type":"code","metadata":{"id":"W9i9QGnXUHXf"},"source":["# 説明変数を作成する\n","data_e = features\n","print(data_e)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1IxJJv4UHXg"},"source":["### モデル構築"]},{"cell_type":"code","metadata":{"id":"OfPM5ZdTUHXg"},"source":["from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","# 決定木のモデル構築を実行する\n","clf = DecisionTreeClassifier(max_depth=2)\n","clf = clf.fit(data_e, data_o)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wr8lRqxRUHXg"},"source":["### 結果の描画"]},{"cell_type":"code","metadata":{"id":"hpBl-_WefJsh"},"source":["from dtreeviz.trees import dtreeviz\n","\n","# indexの抽出\n","x_0 = df_info.resample('M').count()\n","x_0 = x_0.drop(x_0.columns.values,axis=1)\n","time_index = x_0.index\n","print(time_index)\n","\n","# 決定木を描画\n","viz = dtreeviz(\n","    clf,\n","    data_e, \n","    data_o,\n","    target_name='Class',\n","    feature_names=time_index,\n","    class_names=['False','True'],\n",") \n","viz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aT8NJe62UHXg"},"source":["## 2-7. 決定木の分類結果を可視化し、分類精度を評価しよう"]},{"cell_type":"markdown","metadata":{"id":"2MbPXp8eUHXh"},"source":["### 分類結果の可視化"]},{"cell_type":"code","metadata":{"id":"rn2t6oLUUHXh"},"source":["from sklearn.decomposition import PCA\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as pat\n","\n","# 分類を実施\n","pred_tree = clf.predict(data_e)\n","\n","# 主成分分析を実施\n","pca = PCA()\n","pca.fit(features)\n","# 特徴ベクトルを主成分に変換\n","transformed = pca.fit_transform(features)\n","# 可視化\n","plt.figure(figsize=(12, 8))\n","plt.scatter(transformed[:,0],transformed[:,1],c=pred_class)\n","for i in range(len(transformed)):\n","    if pred_tree[i]==1:\n","        if pred_class[i]==1:\n","            temp_color = \"k\"\n","            temp_lw = 1.0\n","        else:\n","            temp_color = \"b\"\n","            temp_lw = 3.0\n","        circle = pat.Circle(xy=(transformed[i,0],transformed[i,1]), radius=1.0, ec=temp_color ,fill=False, linewidth = temp_lw)\n","        plt.axes().add_artist(circle)\n","    else:\n","        if pred_class[i]==1:\n","            temp_color = \"r\"\n","            temp_lw = 3.0\n","            circle = pat.Circle(xy=(transformed[i,0],transformed[i,1]), radius=1.0, ec=temp_color ,fill=False, linewidth = temp_lw)\n","            plt.axes().add_artist(circle)\n","    text = str(i) + \"(\" + str(pred_class[i]) + \")\"\n","    plt.text(transformed[i,0],transformed[i,1],text)\n","plt.show()\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ci_H0qpnUHXh"},"source":["### 混同行列の出力"]},{"cell_type":"code","metadata":{"id":"ww7eRAJzUHXh"},"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(data_o, pred_tree)\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ulvWk1LNUHXh"},"source":["## 2-8. 予測の精度を評価する流れを理解しよう"]},{"cell_type":"markdown","metadata":{"id":"5VjCVeZGUHXi"},"source":["### データセットを訓練データとテストデータに分割"]},{"cell_type":"code","metadata":{"id":"lSekvmIYUHXi"},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(features,data_o)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9h08BWfUHXi"},"source":["### 訓練データによるモデル構築"]},{"cell_type":"code","metadata":{"id":"SANvEdfhUHXi"},"source":["from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","clf = DecisionTreeClassifier(max_depth=2)\n","clf = clf.fit(x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqbv_0SrUHXi"},"source":["### テストデータによる評価"]},{"cell_type":"code","metadata":{"id":"irFkvi6UUHXi"},"source":["from sklearn.metrics import confusion_matrix\n","\n","# スコア計算\n","score = clf.score(x_test, y_test)\n","print(\"スコア:\",score)\n","\n","# 混同行列生成\n","pred_tree = clf.predict(x_test)\n","cm = confusion_matrix(y_test, pred_tree)\n","print(\"混同行列\")\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yLlGC4FiUHXj"},"source":["## 2-9. さまざまな分類アルゴリズムを比較しよう"]},{"cell_type":"markdown","metadata":{"id":"lQCBRgSAUHXj"},"source":["### ランダムフォレストとの比較"]},{"cell_type":"code","metadata":{"id":"0_KQuTvfUHXj"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import confusion_matrix\n","\n","# データセットを訓練データとテストデータに分割\n","x_train, x_test, y_train, y_test = train_test_split(features,data_o)\n","\n","# 訓練データによるモデル構築\n","model = RandomForestClassifier(bootstrap=True, n_estimators=10, max_depth=None, random_state=1)\n","clf = model.fit(x_train, y_train)\n","\n","# テストデータによる評価\n","# スコア計算\n","score = clf.score(x_test, y_test)\n","print(\"スコア:\",score)\n","\n","# 混同行列生成\n","pred_tree = clf.predict(x_test)\n","cm = confusion_matrix(y_test, pred_tree)\n","print(\"混同行列\")\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VhZ5GDHjUHXj"},"source":["### SVMとの比較"]},{"cell_type":"code","metadata":{"id":"5cDSCGEyUHXj"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix\n","\n","# データセットを訓練データとテストデータに分割\n","x_train, x_test, y_train, y_test = train_test_split(features,data_o)\n","\n","# 訓練データによるモデル構築\n","model = SVC(kernel='rbf')\n","clf = model.fit(x_train, y_train)\n","\n","# テストデータによる評価\n","# スコア計算\n","score = clf.score(x_test, y_test)\n","print(\"スコア:\",score)\n","\n","# 混同行列生成\n","pred_tree = clf.predict(x_test)\n","cm = confusion_matrix(y_test, pred_tree)\n","print(\"混同行列\")\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Isl-jFswUHXk"},"source":["## 2-10. サポートベクトル回帰によって時系列予測をしてみよう"]},{"cell_type":"code","metadata":{"id":"FKVQvFXBUHXk"},"source":["from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","\n","# データを作成\n","data_target = data_e[data_o==1]\n","data_y = data_target\n","data_x = np.stack([np.arange(0,len(data_target[0])) for _ in range(len(data_target))], axis=0)\n","data_y = np.ravel(data_y)\n","data_x = np.ravel(data_x)\n","\n","# データセットを訓練データとテストデータに分割\n","x_train, x_test, y_train, y_test = train_test_split(data_x,data_y)\n","\n","# 訓練データによるモデル構築（サポートベクトル回帰）\n","model = svm.SVR(kernel='rbf', C=1)\n","reg = model.fit(x_train.reshape(-1, 1),y_train.reshape(-1, 1))\n","\n","# 予測曲線を描画\n","x_pred = np.arange(len(data_target[0])).reshape(-1, 1)\n","y_pred = model.predict(x_pred)\n","plt.plot(data_x,data_y,\"k.\")\n","plt.plot(x_pred,y_pred,\"r.-\")\n","plt.show()\n","\n","# 決定係数R^2\n","reg.score(x_test.reshape(-1, 1),y_test.reshape(-1, 1))"],"execution_count":null,"outputs":[]}]}